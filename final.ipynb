{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALTEGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from graph_models import SageModel, inference, DotPredictor, GATModel, DeepGAT, MLP\n",
    "from gensim.models import KeyedVectors\n",
    "from utils import edge_train_val_split\n",
    "from graph_models import train_classif\n",
    "\n",
    "from preprocessing import read_graph, retrieve_subgraph\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from author import load_author_embeddings_avg, load_common_author_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499\n",
      "Number of edges: 1091955\n",
      "Number of authors : 174961\n",
      "The minimum degree of the nodes in the graph is : 1\n",
      "The maximum degree of the nodes in the graph is : 3037\n",
      "The mean degree of the nodes in the graph is : 15.76841710048448\n",
      "The median degree of the nodes in the graph is : 9.0\n",
      "Number of nodes in subgraph: 138499\n",
      "Number of edges in subgraph: 1091955\n"
     ]
    }
   ],
   "source": [
    "G, abstracts, text_per_author, author_per_text = read_graph()\n",
    "G = retrieve_subgraph(G, min_nb_nodes=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')\n",
    "doc2vec_model= Doc2Vec.load(\"d2v.model\")\n",
    "for i, node in enumerate(G.nodes()):\n",
    "    G.nodes[int(node)]['id'] = int(node)\n",
    "    G.nodes[int(node)]['feat'] = wv[int(node)]\n",
    "    G.nodes[int(node)]['abstract_feat'] =  doc2vec_model.dv.get_vector(int(node))\n",
    "\n",
    "del wv, doc2vec_model\n",
    "\n",
    "G = load_common_author_embeddings(G, text_per_author, author_per_text)\n",
    "G = load_author_embeddings_avg(G, text_per_author, author_per_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.from_networkx(G, node_attrs=['id','feat', 'abstract_feat', 'feat_com_authors', 'avg_authors_feature']) # already undirected\n",
    "graph.ndata['_ID'] = torch.arange(graph.num_nodes())\n",
    "node_features = graph.ndata['feat']\n",
    "num_features = node_features.shape[1]\n",
    "\n",
    "device = torch.device('cpu')\n",
    "best_model_path = 'gat_model_1.pt'\n",
    "model = GATModel(node_features.shape[1], 64, 4, F.elu).to(device)\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "node_embeddings = model.get_hidden(graph, node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1091955/1091955 [00:05<00:00, 190817.50it/s]\n"
     ]
    }
   ],
   "source": [
    "src = []\n",
    "dst = []\n",
    "for edge in tqdm(G.edges()):\n",
    "    src.append(edge[0])\n",
    "    dst.append(edge[1])\n",
    "G_dir = dgl.graph((src, dst))\n",
    "del src, dst\n",
    "for feat in ['_ID', 'abstract_feat', 'feat_com_authors', 'avg_authors_feature']:\n",
    "    G_dir.ndata[feat] = graph.ndata[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_feat = G_dir.ndata['abstract_feat']\n",
    "avg_authors_feature = G_dir.ndata['avg_authors_feature']\n",
    "feat_com_authors = G_dir.ndata['feat_com_authors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eid_train, eid_val = edge_train_val_split(G_dir, val_size=0.3)\n",
    "device = torch.device('cuda')\n",
    "negative_sampler = dgl.dataloading.negative_sampler.Uniform(3)\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([0, 0]) # We need no message flows\n",
    "train_classif_dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "    # The following arguments are specific to NodeDataLoader.\n",
    "    G_dir,                                  # The graph\n",
    "    eid_train,  # The edges to iterate over\n",
    "    sampler,                                # The neighbor sampler\n",
    "    negative_sampler=negative_sampler,      \n",
    "    device=device,                         \n",
    "    batch_size=1024,    \n",
    "    shuffle=True,       # Whether to shuffle the nodes for every epoch\n",
    "    drop_last=False,    # Whether to drop the last incomplete batch\n",
    "    num_workers=0       # Number of sampler processes\n",
    ")\n",
    "val_classif_dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "    # The following arguments are specific to NodeDataLoader.\n",
    "    G_dir,                                  # The graph \n",
    "    eid_val,  # The edges to iterate over\n",
    "    sampler,                                # The neighbor sampler\n",
    "    negative_sampler=negative_sampler,      \n",
    "    device=device,                         \n",
    "    batch_size=1024,    \n",
    "    shuffle=True,       # Whether to shuffle the nodes for every epoch\n",
    "    drop_last=False,    # Whether to drop the last incomplete batch\n",
    "    num_workers=0       # Number of sampler processes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_embeddings = torch.cat([node_embeddings, abstract_feat, avg_authors_feature], dim=1)\n",
    "input_size = final_embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "epochs = 10\n",
    "mlp = MLP(n_hidden=2*128, n_input=2*input_size).to(device)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [01:40<00:00,  7.44it/s, loss=0.108] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Train mean loss 0.21287320079493874 : Val mean loss 0.11022816854529083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:23<00:00, 32.25it/s, loss=0.088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Train mean loss 0.09547843435003735 : Val mean loss 0.08881878650281579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:23<00:00, 32.38it/s, loss=0.084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 : Train mean loss 0.08298943502955647 : Val mean loss 0.08190084788948297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:22<00:00, 33.85it/s, loss=0.088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 : Train mean loss 0.07775782405771564 : Val mean loss 0.0790490783052519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:20<00:00, 36.17it/s, loss=0.072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 : Train mean loss 0.07426298217202126 : Val mean loss 0.07758342307060957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:22<00:00, 32.75it/s, loss=0.081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 : Train mean loss 0.07218268763528292 : Val mean loss 0.07536243255017325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:22<00:00, 32.82it/s, loss=0.069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 : Train mean loss 0.070121929388608 : Val mean loss 0.074438983167056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:19<00:00, 37.96it/s, loss=0.072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 : Train mean loss 0.06834862002207731 : Val mean loss 0.07303975694812834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:19<00:00, 38.15it/s, loss=0.069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 : Train mean loss 0.0672342618914892 : Val mean loss 0.07289433757541701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:20<00:00, 36.93it/s, loss=0.075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 : Train mean loss 0.06605953419982509 : Val mean loss 0.07204198179533705\n"
     ]
    }
   ],
   "source": [
    "train_classif(\n",
    "    mlp, \n",
    "    final_embeddings, \n",
    "    train_classif_dataloader, \n",
    "    val_classif_dataloader, \n",
    "    criterion, \n",
    "    device,\n",
    "    optimizer, \n",
    "    epochs=10, \n",
    "    name_model='mlp_1.pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model names   |      Model type      |  Hidden features | input variables |  Train acc |\n",
    "|----------|:-------------:|------:|--------|----------|\n",
    "| mlp_1 |  MLP | 256 | gat_1 - doc2vec - avg_authors_feature |  |  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eid_train, eid_val = edge_train_val_split(G_dir, val_size=0.001)\n",
    "device = torch.device('cuda')\n",
    "negative_sampler = dgl.dataloading.negative_sampler.Uniform(3)\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([0, 0]) # We need no message flows\n",
    "train_classif_dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "    # The following arguments are specific to NodeDataLoader.\n",
    "    G_dir,                                  # The graph\n",
    "    eid_train,  # The edges to iterate over\n",
    "    sampler,                                # The neighbor sampler\n",
    "    negative_sampler=negative_sampler,      \n",
    "    device=device,                         \n",
    "    batch_size=1024,    \n",
    "    shuffle=True,       # Whether to shuffle the nodes for every epoch\n",
    "    drop_last=False,    # Whether to drop the last incomplete batch\n",
    "    num_workers=0       # Number of sampler processes\n",
    ")\n",
    "val_classif_dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "    # The following arguments are specific to NodeDataLoader.\n",
    "    G_dir,                                  # The graph \n",
    "    eid_val,  # The edges to iterate over\n",
    "    sampler,                                # The neighbor sampler\n",
    "    negative_sampler=negative_sampler,      \n",
    "    device=device,                         \n",
    "    batch_size=1024,    \n",
    "    shuffle=True,       # Whether to shuffle the nodes for every epoch\n",
    "    drop_last=False,    # Whether to drop the last incomplete batch\n",
    "    num_workers=0       # Number of sampler processes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "epochs = 10\n",
    "mlp = MLP(n_hidden=2*128, n_input=2*input_size).to(device)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1066/1066 [00:29<00:00, 35.56it/s, loss=0.093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Train mean loss 0.1808507614690412 : Val mean loss 0.08969736471772194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1066/1066 [00:29<00:00, 36.17it/s, loss=0.072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Train mean loss 0.08726413006322917 : Val mean loss 0.08220713213086128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1066/1066 [00:32<00:00, 32.90it/s, loss=0.073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 : Train mean loss 0.07828535139211235 : Val mean loss 0.069878239184618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1066/1066 [00:30<00:00, 35.47it/s, loss=0.081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 : Train mean loss 0.07404372810366901 : Val mean loss 0.0670417845249176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1066/1066 [00:30<00:00, 35.05it/s, loss=0.076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 : Train mean loss 0.07145227479624368 : Val mean loss 0.06138957291841507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1066/1066 [00:31<00:00, 34.07it/s, loss=0.061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 : Train mean loss 0.0691420832652368 : Val mean loss 0.08166980370879173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1066/1066 [00:29<00:00, 36.57it/s, loss=0.069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 : Train mean loss 0.06763134123390543 : Val mean loss 0.07511237636208534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1066/1066 [00:27<00:00, 38.67it/s, loss=0.061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 : Train mean loss 0.06638705389011533 : Val mean loss 0.05774259753525257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1066/1066 [00:28<00:00, 37.01it/s, loss=0.074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 : Train mean loss 0.06539436417507745 : Val mean loss 0.07967415824532509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1066/1066 [00:32<00:00, 32.64it/s, loss=0.077]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 : Train mean loss 0.06454025934088632 : Val mean loss 0.06590183265507221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_classif(\n",
    "    mlp, \n",
    "    final_embeddings, \n",
    "    train_classif_dataloader, \n",
    "    val_classif_dataloader, \n",
    "    criterion, \n",
    "    device,\n",
    "    optimizer, \n",
    "    epochs=10, \n",
    "    name_model='mlp_1.pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import retrieve_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp = MLP(n_hidden=128, n_input=2*114).to(device)\n",
    "#mlp.load_state_dict(torch.load('clf_gat_model_1_plus_doc.pt'))\n",
    "\n",
    "X_test = retrieve_embeddings(G_dir, final_embeddings)\n",
    "with torch.no_grad():\n",
    "    y_tens = torch.sigmoid(mlp(X_test.to(device))).cpu().numpy()\n",
    "y_pred = y_tens[:,0]\n",
    "\n",
    "\n",
    "predictions = zip(range(len(y_pred)), y_pred)\n",
    "with open(\"submission_mlp_1.csv\",\"w\") as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(['id','predicted'])\n",
    "    for row in predictions:\n",
    "        csv_out.writerow(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6c713541ad13855d4a4355aac6ffc47bbcd60df7053ae4f5574f5a879b69510"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
