{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import csv\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from preprocessing import read_graph, retrieve_subgraph\n",
    "\n",
    "\n",
    "device = 'cpu' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "doc2vec_model= Doc2Vec.load(\"d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499\n",
      "Number of edges: 1091955\n",
      "Number of authors : 174961\n",
      "The minimum degree of the nodes in the graph is : 1\n",
      "The maximum degree of the nodes in the graph is : 3037\n",
      "The mean degree of the nodes in the graph is : 15.76841710048448\n",
      "The median degree of the nodes in the graph is : 9.0\n",
      "Number of nodes in subgraph: 138499\n",
      "Number of edges in subgraph: 1091955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dutot\\Utilities\\anaconda3\\lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  return th.as_tensor(data, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=138499, num_edges=2183910,\n",
      "      ndata_schemes={'id': Scheme(shape=(), dtype=torch.int64), 'feat': Scheme(shape=(50,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "G, abstract, _, _ = read_graph()\n",
    "G = retrieve_subgraph(G, min_nb_nodes=-1)\n",
    "attrs_n = []\n",
    "for i, node in enumerate(G.nodes()):\n",
    "    G.nodes[int(node)]['id'] = int(node)\n",
    "    G.nodes[int(node)]['feat'] = doc2vec_model.dv.get_vector(int(node))\n",
    "\n",
    "G = dgl.from_networkx(G, node_attrs=['id','feat']) # already undirected\n",
    "print(G)\n",
    "G.ndata['_ID'] = torch.arange(G.num_nodes())\n",
    "node_features = G.ndata['feat']\n",
    "num_features = node_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "negative_sampler = dgl.dataloading.negative_sampler.Uniform(5)\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([-1, -1])\n",
    "train_dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "    # The following arguments are specific to NodeDataLoader.\n",
    "    G,                                  # The graph\n",
    "    torch.arange(G.number_of_edges()),  # The edges to iterate over\n",
    "    sampler,                                # The neighbor sampler\n",
    "    negative_sampler=negative_sampler,      # The negative sampler\n",
    "    device=device,                          # Put the MFGs on CPU or GPU\n",
    "    # The following arguments are inherited from PyTorch DataLoader.\n",
    "    batch_size=2*1024,    # Batch size on peut faire x2\n",
    "    shuffle=True,       # Whether to shuffle the nodes for every epoch\n",
    "    drop_last=False,    # Whether to drop the last incomplete batch\n",
    "    num_workers=0       # Number of sampler processes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_models import GATModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "from graph_models import SageModel, inference, DotPredictor\n",
    "model = GATModel(node_features.shape[1], 64, 4, F.elu).to(device)\n",
    "predictor = DotPredictor().to(device)\n",
    "opt = torch.optim.Adam(list(model.parameters()) + list(predictor.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1067/1067 [10:05<00:00,  1.76it/s, loss=0.614]\n",
      "100%|██████████| 1067/1067 [10:00<00:00,  1.78it/s, loss=0.603]\n",
      "  0%|          | 4/1067 [00:02<12:44,  1.39it/s, loss=0.608]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-449cdfa4f39f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmfgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrcdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mpos_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mneg_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dutot\\Documents\\Travail\\Cours\\4A\\MVA\\ALTEGRAD\\Challenge\\data_challenge_2021\\graph_models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, mfgs, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmfgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mh_dst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmfgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_dst_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgat1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_dst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\dgl\\heterograph.py\u001b[0m in \u001b[0;36mnum_dst_nodes\u001b[1;34m(self, ntype)\u001b[0m\n\u001b[0;32m   2462\u001b[0m         \"\"\"\n\u001b[0;32m   2463\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mntype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2464\u001b[1;33m             return sum([self._graph.number_of_nodes(self.get_ntype_id_from_dst(nty))\n\u001b[0m\u001b[0;32m   2465\u001b[0m                         for nty in self.dsttypes])\n\u001b[0;32m   2466\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\dgl\\heterograph.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2462\u001b[0m         \"\"\"\n\u001b[0;32m   2463\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mntype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2464\u001b[1;33m             return sum([self._graph.number_of_nodes(self.get_ntype_id_from_dst(nty))\n\u001b[0m\u001b[0;32m   2465\u001b[0m                         for nty in self.dsttypes])\n\u001b[0;32m   2466\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\dgl\\heterograph_index.py\u001b[0m in \u001b[0;36mnumber_of_nodes\u001b[1;34m(self, ntype)\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \"\"\"\n\u001b[1;32m--> 298\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_CAPI_DGLHeteroNumVertices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnumber_of_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\dgl\\_ffi\\_ctypes\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mret_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDGLValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mret_tcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         check_call(_LIB.DGLFuncCall(\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import sklearn.metrics\n",
    "device = torch.device('cuda')\n",
    "best_accuracy = 0\n",
    "#best_model_path = 'model3.pt'\n",
    "for epoch in range(2):\n",
    "    with tqdm.tqdm(train_dataloader) as tq:\n",
    "        for step, (input_nodes, pos_graph, neg_graph, mfgs) in enumerate(tq):\n",
    "            # feature copy from CPU to GPU takes place here\n",
    "            inputs = mfgs[0].srcdata['feat']\n",
    "\n",
    "            outputs = model(mfgs, inputs)\n",
    "            pos_score = predictor(pos_graph, outputs)\n",
    "            neg_score = predictor(neg_graph, outputs)\n",
    "\n",
    "            score = torch.cat([pos_score, neg_score])\n",
    "            label = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)])\n",
    "            loss = F.binary_cross_entropy_with_logits(score, label)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            tq.set_postfix({'loss': '%.03f' % loss.item()}, refresh=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GATConv\n",
    "\n",
    "class GATModel(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_heads, nonlinearity):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.gat1 = GATConv(in_feats, h_feats, num_heads)\n",
    "        self.gat2 = GATConv(h_feats * num_heads, h_feats, num_heads)\n",
    "        #self.gat3 = GATConv(h_feats * num_heads, h_feats)\n",
    "        self.h_feats = h_feats\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def forward(self, mfgs, x):\n",
    "        h_dst = x[:mfgs[0].num_dst_nodes()]\n",
    "        h = self.gat1(mfgs[0], (x, h_dst))\n",
    "        h = h.view(-1, h.size(1) * h.size(2))\n",
    "        h = self.nonlinearity(h)\n",
    "        h_dst = h[:mfgs[1].num_dst_nodes()]\n",
    "        h = self.gat2(mfgs[1], (h, h_dst))\n",
    "        h = torch.mean(h, dim=1)\n",
    "        return h\n",
    "\n",
    "    def get_hidden(self, graph, x):\n",
    "        with torch.no_grad():\n",
    "            h = self.gat1(graph, x)\n",
    "            h = h.view(-1, h.size(1) * h.size(2))\n",
    "            h = self.nonlinearity(h)\n",
    "            h = self.gat2(graph, h)\n",
    "            h = torch.mean(h, dim=1)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and getting embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "best_model_path = 'model3.pt'\n",
    "model = GATModel(node_features.shape[1], 64, 4, F.elu).to(device)\n",
    "#model = SageModel(node_features.shape[1], 128).to(device)\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "node_embeddings = model.get_hidden(G, node_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "negative_sampler = dgl.dataloading.negative_sampler.Uniform(1)\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([0, 0]) # We need no message flows\n",
    "train_classif_dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "    # The following arguments are specific to NodeDataLoader.\n",
    "    G,                                  # The graph\n",
    "    torch.arange(G.number_of_edges()),  # The edges to iterate over\n",
    "    sampler,                                # The neighbor sampler\n",
    "    negative_sampler=negative_sampler,      \n",
    "    device=device,                         \n",
    "    batch_size=1024,    \n",
    "    shuffle=True,       # Whether to shuffle the nodes for every epoch\n",
    "    drop_last=False,    # Whether to drop the last incomplete batch\n",
    "    num_workers=0       # Number of sampler processes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_models import MLP  \n",
    "\n",
    "device = torch.device('cuda')\n",
    "epochs = 200\n",
    "mlp = MLP(n_hidden=128, n_input=2*64).to(device)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, embeddings, dataloader, criterion, epochs=10):\n",
    "    best_model_path = 'classif.pt'\n",
    "    min_loss=np.inf\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        with tqdm.tqdm(dataloader) as tq:\n",
    "            for step, (input_nodes, pos_graph, neg_graph, _) in enumerate(tq):\n",
    "                with torch.no_grad():\n",
    "                    src, dst = pos_graph.edges()\n",
    "                    src_emb = embeddings[pos_graph.nodes[src].data['_ID']]\n",
    "                    dst_emb = embeddings[pos_graph.nodes[dst].data['_ID']]\n",
    "                    x = torch.cat([src_emb, dst_emb], dim=1)\n",
    "                    n_pos = x.shape[0]\n",
    "\n",
    "                    src_neg, dst_neg = neg_graph.edges()\n",
    "                    src_emb_neg = embeddings[neg_graph.nodes[src_neg].data['_ID']]\n",
    "                    dst_emb_neg = embeddings[neg_graph.nodes[dst_neg].data['_ID']]\n",
    "                    x_neg = torch.cat([src_emb_neg, dst_emb_neg], dim=1)\n",
    "                    n_neg = x_neg.shape[0]\n",
    "                    \n",
    "                x_tot = torch.cat([x, x_neg], dim=0).to(device)\n",
    "                y = model(x_tot)\n",
    "                \n",
    "                pos_label = torch.ones(n_pos)\n",
    "                target = torch.cat([pos_label, torch.zeros(n_neg)]).to(device)\n",
    "\n",
    "                loss = criterion(y.squeeze(), target)\n",
    "                losses.append(loss.item())\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                tq.set_postfix({'loss': '%.03f' % loss.item()}, refresh=False)\n",
    "\n",
    "        if np.mean(losses) < min_loss:\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        print(f'Epoch {epoch} : mean loss {np.mean(losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2133/2133 [00:47<00:00, 45.15it/s, loss=0.108]\n",
      "  0%|          | 0/2133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : mean loss 0.15045701152441146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2133/2133 [00:52<00:00, 40.26it/s, loss=0.095]\n",
      "  0%|          | 0/2133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : mean loss 0.1071010065145801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2133/2133 [00:54<00:00, 39.18it/s, loss=0.104]\n",
      "  0%|          | 1/2133 [00:00<05:33,  6.39it/s, loss=0.094]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 : mean loss 0.1028701452947926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2133/2133 [00:50<00:00, 42.40it/s, loss=0.115]\n",
      "  0%|          | 0/2133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 : mean loss 0.10074050194617454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2133/2133 [00:50<00:00, 42.56it/s, loss=0.091]\n",
      "  0%|          | 1/2133 [00:00<06:20,  5.60it/s, loss=0.104]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 : mean loss 0.09960134188040734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2133/2133 [00:48<00:00, 43.59it/s, loss=0.110]\n",
      "  0%|          | 1/2133 [00:00<06:03,  5.86it/s, loss=0.086]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 : mean loss 0.09864201795255641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2133/2133 [00:53<00:00, 39.52it/s, loss=0.108]\n",
      "  0%|          | 0/2133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 : mean loss 0.09764063794583264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2133/2133 [00:53<00:00, 40.16it/s, loss=0.090]\n",
      "  0%|          | 1/2133 [00:00<06:18,  5.63it/s, loss=0.101]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 : mean loss 0.0972103982730701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 241/2133 [00:06<00:48, 39.24it/s, loss=0.104]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-61c30868b80b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_classif_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-94294c8a2f19>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, embeddings, dataloader, criterion)\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[0mtq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'%.03f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(mlp, node_embeddings, train_classif_dataloader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_embeddings(G, embeddings):\n",
    "    node_pairs = list()\n",
    "    with open('test.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            t = line.split(',')\n",
    "            node_pairs.append((int(t[0]), int(t[1])))\n",
    "    x = torch.zeros((len(node_pairs), 2*embeddings.shape[1]))\n",
    "    for i, (src, dst) in enumerate(node_pairs):\n",
    "        src_emb = embeddings[G.nodes[src].data['_ID']]\n",
    "        dst_emb = embeddings[G.nodes[dst].data['_ID']]\n",
    "        line = torch.cat([src_emb, dst_emb], dim=1)\n",
    "        x[i,:] = line\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from preprocessing import retrieve_embeddings\n",
    "X_test = retrieve_embeddings(G, node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_tens = torch.sigmoid(mlp(X_test.to(device))).cpu().numpy()\n",
    "y_pred = y_tens[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def retrieve_embeddings(G, embeddings):\n",
    "    node_pairs = list()\n",
    "    with open('test.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            t = line.split(',')\n",
    "            node_pairs.append((int(t[0]), int(t[1])))\n",
    "    x = torch.zeros((len(node_pairs), 2*embeddings.shape[1]))\n",
    "    for i, (src, dst) in enumerate(node_pairs):\n",
    "        src_emb = embeddings[G.nodes[src].data['_ID']]\n",
    "        dst_emb = embeddings[G.nodes[dst].data['_ID']]\n",
    "        line = torch.cat([src_emb, dst_emb], dim=1)\n",
    "        x[i,:] = line\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = zip(range(len(y_pred)), y_pred)\n",
    "with open(\"submission_gat.csv\",\"w\") as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(['id','predicted'])\n",
    "    for row in predictions:\n",
    "        csv_out.writerow(row) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from preprocessing import read_graph\n",
    "from time import time \n",
    "from nltk.tokenize import word_tokenize\n",
    "_, abstracts, _, _ = read_graph()\n",
    "# ~4 mins\n",
    "data = list(abstract.values())\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 200\n",
    "vec_size = 50\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=2,\n",
    "                hs=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    t_start = time()\n",
    "    \n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=1)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "    print('Epoch {0}. Elapsed {1} s'.format(epoch, time() - t_start))\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
