{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import csv\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "from graph_models import SageModel, inference, DotPredictor, GATModel, DeepGAT\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from preprocessing import read_graph, retrieve_subgraph\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "\n",
    "device = 'cpu' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node2Vec authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import csv\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.nn import Node2Vec\n",
    "\n",
    "\n",
    "from preprocessing import read_graph, retrieve_subgraph, create_author_graph, create_commun_authors_papers_graph\n",
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I) Graph of author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499\n",
      "Number of edges: 1091955\n",
      "Number of authors : 174961\n",
      "The minimum degree of the nodes in the graph is : 0\n",
      "The maximum degree of the nodes in the graph is : 677\n",
      "The mean degree of the nodes in the graph is : 6.504683900983648\n",
      "The median degree of the nodes in the graph is : 4.0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'node2vec_authors_64dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8ac45a4b32f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'node2vec_authors_64dim'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'node2vec_authors_64dim'"
     ]
    }
   ],
   "source": [
    "G, abstracts, text_per_author, author_per_text = read_graph()\n",
    "\n",
    "\n",
    "G_authors = create_author_graph(text_per_author, author_per_text)\n",
    "\n",
    "\n",
    "degree_sequence = np.array([G_authors.degree(node) for node in G_authors.nodes()])\n",
    "min_nb_nodes = 0\n",
    "print('The minimum degree of the nodes in the graph is :', min(degree_sequence))\n",
    "print('The maximum degree of the nodes in the graph is :', max(degree_sequence))\n",
    "print('The mean degree of the nodes in the graph is :', np.mean(degree_sequence))\n",
    "print('The median degree of the nodes in the graph is :', np.median(degree_sequence))\n",
    "\n",
    "\n",
    "\n",
    "for i, node in enumerate(G_authors.nodes()):\n",
    "    G_authors.nodes[str(node)]['id'] = i\n",
    "G_authors_train = from_networkx(G_authors) # already undirected\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Node2Vec(G_authors_train.edge_index, embedding_dim= 64, walk_length=30,\n",
    "                    context_size=10, walks_per_node=20,\n",
    "                    num_negative_samples=1, p=1, q=1, sparse=True).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II) Graph of co-authored paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.data import BiasedRandomWalk\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "def node2vec_embedding(graph, name):\n",
    "    rw = BiasedRandomWalk(graph)\n",
    "    walks = rw.run(graph.nodes(), n=num_walks, length=walk_length, p=p, q=q)\n",
    "    print(f\"Number of random walks for '{name}': {len(walks)}\")\n",
    "\n",
    "    model = Word2Vec(\n",
    "        walks,\n",
    "        vector_size=dimensions,\n",
    "        window=window_size,\n",
    "        min_count=0,\n",
    "        sg=1,\n",
    "        workers=workers,\n",
    "        iter=num_iter,\n",
    "    )\n",
    "\n",
    "    def get_embedding(u):\n",
    "        return model.wv[u]\n",
    "\n",
    "    return get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1.0\n",
    "q = 1.0\n",
    "dimensions = 50\n",
    "num_walks = 10\n",
    "walk_length = 80\n",
    "window_size = 10\n",
    "num_iter = 1\n",
    "workers = multiprocessing.cpu_count() - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499\n",
      "Number of edges: 1091955\n",
      "Number of authors : 174961\n",
      "The minimum degree of the nodes in the graph is : 1\n",
      "The maximum degree of the nodes in the graph is : 3037\n",
      "The mean degree of the nodes in the graph is : 15.76841710048448\n",
      "The median degree of the nodes in the graph is : 9.0\n",
      "Number of nodes in subgraph: 138499\n",
      "Number of edges in subgraph: 1091955\n"
     ]
    }
   ],
   "source": [
    "G, abstract, _, _ = read_graph()\n",
    "G = retrieve_subgraph(G, min_nb_nodes=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph import StellarGraph\n",
    "graph = StellarGraph.from_networkx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "    walks,\n",
    "    vector_size=dimensions,\n",
    "    window=window_size,\n",
    "    min_count=0,\n",
    "    sg=1,\n",
    "    workers=workers,\n",
    "    epochs=1\n",
    ")\n",
    "\n",
    "word_vectors = model.wv\n",
    "\n",
    "word_vectors.save(\"word2vec.wordvectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499\n",
      "Number of edges: 1091955\n",
      "Number of authors : 174961\n",
      "The minimum degree of the nodes in the graph is : 1\n",
      "The maximum degree of the nodes in the graph is : 3037\n",
      "The mean degree of the nodes in the graph is : 15.76841710048448\n",
      "The median degree of the nodes in the graph is : 9.0\n",
      "Number of nodes in subgraph: 138499\n",
      "Number of edges in subgraph: 1091955\n"
     ]
    }
   ],
   "source": [
    "graph, abstract, _, _ = read_graph()\n",
    "graph = retrieve_subgraph(graph, min_nb_nodes=-1)\n",
    "attrs_n = []\n",
    "for i, node in enumerate(graph.nodes()):\n",
    "    graph.nodes[int(node)]['id'] = int(node)\n",
    "    feat_vec = doc2vec_model.dv.get_vector(int(node)) # torch.rand(size=doc2vec_model.dv.get_vector(int(node)).shape)\n",
    "    graph.nodes[int(node)]['feat'] = feat_vec\n",
    "\n",
    "graph = dgl.from_networkx(graph, node_attrs=['id','feat']) # already undirected\n",
    "graph.ndata['_ID'] = torch.arange(graph.num_nodes())\n",
    "\n",
    "node_features = graph.ndata['feat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499\n",
      "Number of edges: 1091955\n",
      "Number of authors : 174961\n",
      "The minimum degree of the nodes in the graph is : 1\n",
      "The maximum degree of the nodes in the graph is : 3037\n",
      "The mean degree of the nodes in the graph is : 15.76841710048448\n",
      "The median degree of the nodes in the graph is : 9.0\n",
      "Number of nodes in subgraph: 138499\n",
      "Number of edges in subgraph: 1091955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dutot\\Utilities\\anaconda3\\lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  return th.as_tensor(data, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=138499, num_edges=2183910,\n",
      "      ndata_schemes={'id': Scheme(shape=(), dtype=torch.int64), 'feat': Scheme(shape=(50,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "G, abstract, _, _ = read_graph()\n",
    "G = retrieve_subgraph(G, min_nb_nodes=-1)\n",
    "attrs_n = []\n",
    "for i, node in enumerate(G.nodes()):\n",
    "    G.nodes[int(node)]['id'] = int(node)\n",
    "    #feat_vec = doc2vec_model.dv.get_vector(int(node)) # torch.rand(size=doc2vec_model.dv.get_vector(int(node)).shape)\n",
    "    G.nodes[int(node)]['feat'] = wv[int(node)]\n",
    "\n",
    "G = dgl.from_networkx(G, node_attrs=['id','feat']) # already undirected\n",
    "print(G)\n",
    "G.ndata['_ID'] = torch.arange(G.num_nodes())\n",
    "\n",
    "node_features = G.ndata['feat']\n",
    "num_features = node_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "negative_sampler = dgl.dataloading.negative_sampler.Uniform(5)\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([-1, -1])\n",
    "train_dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "    # The following arguments are specific to NodeDataLoader.\n",
    "    G,                                  # The graph\n",
    "    torch.arange(G.number_of_edges()),  # The edges to iterate over\n",
    "    sampler,                                # The neighbor sampler\n",
    "    negative_sampler=negative_sampler,      # The negative sampler\n",
    "    device=device,                          # Put the MFGs on CPU or GPU\n",
    "    # The following arguments are inherited from PyTorch DataLoader.\n",
    "    batch_size=2*1024,    # Batch size on peut faire x2\n",
    "    shuffle=True,       # Whether to shuffle the nodes for every epoch\n",
    "    drop_last=False,    # Whether to drop the last incomplete batch\n",
    "    num_workers=0       # Number of sampler processes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "#model = GATModel(node_features.shape[1], 64, 4, F.elu).to(device)\n",
    "model = SageModel(node_features.shape[1], 128).to(device)\n",
    "predictor = DotPredictor().to(device)\n",
    "opt = torch.optim.Adam(list(model.parameters()) + list(predictor.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1067/1067 [03:15<00:00,  5.47it/s, loss=0.420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Train mean loss 0.5861868947995748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1067/1067 [03:17<00:00,  5.41it/s, loss=0.406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Train mean loss 0.40281731105342355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1067/1067 [03:16<00:00,  5.42it/s, loss=0.401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 : Train mean loss 0.3951230390728805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1067/1067 [03:15<00:00,  5.44it/s, loss=0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 : Train mean loss 0.3894567143838877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1067/1067 [03:16<00:00,  5.43it/s, loss=0.391]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 : Train mean loss 0.38569909364906785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "best_accuracy = 0\n",
    "min_loss = np.inf\n",
    "best_model_path = 'sage_model_2.pt'\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    with tqdm(train_dataloader) as tq:\n",
    "        for step, (input_nodes, pos_graph, neg_graph, mfgs) in enumerate(tq):\n",
    "            # feature copy from CPU to GPU takes place here\n",
    "            inputs = mfgs[0].srcdata['feat']\n",
    "\n",
    "            outputs = model(mfgs, inputs)\n",
    "            pos_score = predictor(pos_graph, outputs)\n",
    "            neg_score = predictor(neg_graph, outputs)\n",
    "\n",
    "            score = torch.cat([pos_score, neg_score])\n",
    "            label = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)])\n",
    "            loss = F.binary_cross_entropy_with_logits(score, label)\n",
    "            losses.append(loss.item())\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            tq.set_postfix({'loss': '%.03f' % loss.item()}, refresh=False)\n",
    "    if np.mean(losses) < min_loss:\n",
    "        min_loss = np.mean(losses)\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "    print(f'Epoch {epoch} : Train mean loss {np.mean(losses)}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.615 / 0.622 for DeepGat 1 epoch doc2vec \\\\\n",
    "0.693 / 0.693 : for DeepGat 1 epoch random features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model names   |      Model type      |  Hidden features | n_head | embeddings | Train acc |\n",
    "|----------|:-------------:|------:|--------|----------|---------|\n",
    "| gat_model_1 |  GATModel | 64 | 4 | node2vec | 0.3995 (2 epochs) 0.3897 (5 epochs) |\n",
    "| gat_model_2 |    GATModel |   64 | 4 | doc2vec | 0.3991 (5 epochs) |\n",
    "| sage_model_1 | GraphSage |    64 | | node2vec| 0.4003 (5 epochs)|\n",
    "| sage_model_2 | GraphSage |    128 | | node2vec| 0.3857 (5 epochs)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gat model 1 :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'model3.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and getting embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "best_model_path = 'gat_model_1.pt'\n",
    "model = GATModel(node_features.shape[1], 64, 4, F.elu).to(device)\n",
    "#model = SageModel(node_features.shape[1], 128).to(device)\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "node_embeddings = model.get_hidden(G, node_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499\n",
      "Number of edges: 1091955\n",
      "Number of authors : 174961\n",
      "The minimum degree of the nodes in the graph is : 1\n",
      "The maximum degree of the nodes in the graph is : 3037\n",
      "The mean degree of the nodes in the graph is : 15.76841710048448\n",
      "The median degree of the nodes in the graph is : 9.0\n",
      "Number of nodes in subgraph: 138499\n",
      "Number of edges in subgraph: 1091955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1091955/1091955 [00:05<00:00, 199092.76it/s]\n"
     ]
    }
   ],
   "source": [
    "G_dir, abstract, _, _ = read_graph()\n",
    "G_dir = retrieve_subgraph(G_dir, min_nb_nodes=-1)\n",
    "attrs_n = []\n",
    "for i, node in enumerate(G_dir.nodes()):\n",
    "    G_dir.nodes[int(node)]['id'] = int(node)\n",
    "    #feat_vec = doc2vec_model.dv.get_vector(int(node)) # torch.rand(size=doc2vec_model.dv.get_vector(int(node)).shape)\n",
    "\n",
    "src = []\n",
    "dst = []\n",
    "for edge in tqdm(G_dir.edges()):\n",
    "    src.append(edge[0])\n",
    "    dst.append(edge[1])\n",
    "G_dir = dgl.graph((src, dst))\n",
    "del src, dst\n",
    "G_dir.ndata['_ID'] = G.ndata['_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import edge_train_val_split\n",
    "eid_train, eid_val = edge_train_val_split(G_dir, val_size=0.3)\n",
    "device = torch.device('cuda')\n",
    "negative_sampler = dgl.dataloading.negative_sampler.Uniform(3)\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([0, 0]) # We need no message flows\n",
    "train_classif_dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "    # The following arguments are specific to NodeDataLoader.\n",
    "    G_dir,                                  # The graph\n",
    "    eid_train,  # The edges to iterate over\n",
    "    sampler,                                # The neighbor sampler\n",
    "    negative_sampler=negative_sampler,      \n",
    "    device=device,                         \n",
    "    batch_size=1024,    \n",
    "    shuffle=True,       # Whether to shuffle the nodes for every epoch\n",
    "    drop_last=False,    # Whether to drop the last incomplete batch\n",
    "    num_workers=0       # Number of sampler processes\n",
    ")\n",
    "val_classif_dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "    # The following arguments are specific to NodeDataLoader.\n",
    "    G_dir,                                  # The graph \n",
    "    eid_val,  # The edges to iterate over\n",
    "    sampler,                                # The neighbor sampler\n",
    "    negative_sampler=negative_sampler,      \n",
    "    device=device,                         \n",
    "    batch_size=1024,    \n",
    "    shuffle=True,       # Whether to shuffle the nodes for every epoch\n",
    "    drop_last=False,    # Whether to drop the last incomplete batch\n",
    "    num_workers=0       # Number of sampler processes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_models import MLP  \n",
    "\n",
    "device = torch.device('cuda')\n",
    "epochs = 10\n",
    "mlp = MLP(n_hidden=128, n_input=2*114).to(device)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = torch.cat([node_features, node_embeddings], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([138499, 114])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:18<00:00, 39.88it/s, loss=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Train mean loss 0.25260702123643564 : Val mean loss 0.12270529535599053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:23<00:00, 31.99it/s, loss=0.093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Train mean loss 0.10443901735416537 : Val mean loss 0.09520953253377229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:22<00:00, 33.22it/s, loss=0.082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 : Train mean loss 0.08971355383694571 : Val mean loss 0.08624967820942402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:23<00:00, 31.64it/s, loss=0.091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 : Train mean loss 0.08344800936848604 : Val mean loss 0.08270398410968482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:24<00:00, 30.49it/s, loss=0.076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 : Train mean loss 0.08010178934059628 : Val mean loss 0.08070748989703133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:22<00:00, 32.54it/s, loss=0.085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 : Train mean loss 0.07768091989289645 : Val mean loss 0.07820165122393519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 747/747 [00:24<00:00, 30.73it/s, loss=0.068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 : Train mean loss 0.07591449189058429 : Val mean loss 0.07677419348619878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 217/747 [00:10<00:26, 20.13it/s, loss=0.069]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-c8235bb94434>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgraph_models\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_classif\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m train_classif(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mmlp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0membed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_classif_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dutot\\Documents\\Travail\\Cours\\4A\\MVA\\ALTEGRAD\\Challenge\\data_challenge_2021\\graph_models.py\u001b[0m in \u001b[0;36mtrain_classif\u001b[1;34m(model, embeddings, train_dataloader, val_dataloader, criterion, device, optimizer, epochs, name_model)\u001b[0m\n\u001b[0;32m    176\u001b[0m                     \u001b[0msrc_neg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_neg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneg_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0msrc_emb_neg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneg_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msrc_neg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                     \u001b[0mdst_emb_neg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneg_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdst_neg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                     \u001b[0mx_neg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msrc_emb_neg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_emb_neg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                     \u001b[0mn_neg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_neg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\dgl\\view.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_n_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ntid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\dgl\\heterograph.py\u001b[0m in \u001b[0;36m_get_n_repr\u001b[1;34m(self, ntid, u)\u001b[0m\n\u001b[0;32m   4140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_node_frames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mntid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4141\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4142\u001b[1;33m             \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'u'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4143\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_node_frames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mntid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\dgl\\utils\\checks.py\u001b[0m in \u001b[0;36mprepare_tensor\u001b[1;34m(g, data, name)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midtype\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             raise DGLError('Expect argument \"{}\" to have data type {} and device '\n\u001b[0;32m     34\u001b[0m                            'context {}. But got {} and {}.'.format(\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\dgl\\heterograph.py\u001b[0m in \u001b[0;36midtype\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[0mint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2662\u001b[0m         \"\"\"\n\u001b[1;32m-> 2663\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\dgl\\heterograph_index.py\u001b[0m in \u001b[0;36mdtype\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \"\"\"\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_CAPI_DGLHeteroDataType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Utilities\\anaconda3\\lib\\site-packages\\dgl\\_ffi\\_ctypes\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mret_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDGLValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mret_tcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         check_call(_LIB.DGLFuncCall(\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from graph_models import train_classif\n",
    "train_classif(\n",
    "    mlp, \n",
    "    embed, \n",
    "    train_classif_dataloader, \n",
    "    val_classif_dataloader, \n",
    "    criterion, \n",
    "    device,\n",
    "    optimizer, \n",
    "    epochs=10, \n",
    "    name_model='clf_gat_model_1_plus_doc.pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model names   |      Model type      | Parameters | n lyaer | embeddings | Score |\n",
    "|----------|:-------------:|------:|--------|----------|---------|\n",
    "| gat_model_1 |  GATModel | 64 | 4 | node2vec | 0.25 (10 epochs) |\n",
    "| gat_model_2 |    GATModel |   64 | 4 | doc2vec | 0.3991 (5 epochs) |\n",
    "| clf_sage_model_2 | MLP |    128h | 3 layer | gnn_only| 0.26 on test set (10 epochs)|\n",
    "| sage_model_2 | GraphSage |    128 | | node2vec| 0.3857 (5 epochs)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_models import MLP\n",
    "from preprocessing import retrieve_embeddings\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLP(n_hidden=128, n_input=2*114).to(device)\n",
    "mlp.load_state_dict(torch.load('clf_gat_model_1_plus_doc.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = retrieve_embeddings(G, embed)\n",
    "with torch.no_grad():\n",
    "    y_tens = torch.sigmoid(mlp(X_test.to(device))).cpu().numpy()\n",
    "y_pred = y_tens[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = zip(range(len(y_pred)), y_pred)\n",
    "with open(\"submission_model_gat_1_with_doc.csv\",\"w\") as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(['id','predicted'])\n",
    "    for row in predictions:\n",
    "        csv_out.writerow(row) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from preprocessing import read_graph\n",
    "from time import time \n",
    "from nltk.tokenize import word_tokenize\n",
    "_, abstracts, _, _ = read_graph()\n",
    "# ~4 mins\n",
    "data = list(abstract.values())\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 200\n",
    "vec_size = 50\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=2,\n",
    "                hs=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    t_start = time()\n",
    "    \n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=1)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "    print('Epoch {0}. Elapsed {1} s'.format(epoch, time() - t_start))\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
